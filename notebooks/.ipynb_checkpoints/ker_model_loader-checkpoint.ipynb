{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../ker_model_loader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '../ker_model_loader.py'\n",
    "\n",
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from imodel import Model\n",
    "from custom_functions import cf_metrics, cf_losses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class KER_Model_Loader:\n",
    "    \n",
    "    def __init__(self, Model):\n",
    "        Build = Model._INFO['BUILD'];\n",
    "        Make = Model._INFO['MAKE']\n",
    "        Version = Model._INFO['VERSION']\n",
    "        k = Sequential();\n",
    "        \n",
    "        if(Build == '1'):            \n",
    "            if (Make == '1'):\n",
    "                k.add(LSTM(units=100, activation='relu', input_shape=(Model._D_X_SHAPE[1],Model._D_X_SHAPE[2]) , return_sequences=True ));\n",
    "                k.add(LSTM(units=100, activation='relu'))\n",
    "                k.add(Dense(Model._D_Y_SHAPE[1]));\n",
    "                k.compile(optimizer='adam', loss='mse', metrics=['accuracy']);\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "        elif (Build == '2'):            \n",
    "            if (Make == '1'):\n",
    "                k.add(LSTM(units=100, activation='relu', input_shape=(Model._D_X_SHAPE[1],Model._D_X_SHAPE[2])   ,  return_sequences=True ));\n",
    "                k.add(LSTM(units=100, activation='relu'))\n",
    "                k.add(Dense(Model._D_Y_SHAPE[1]));\n",
    "                k.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "        elif (Build == '3'):            \n",
    "            if (Make == '1'):\n",
    "                k.add(LSTM(units=80, activation='relu', input_shape=(Model._D_X_SHAPE[1],Model._D_X_SHAPE[2])   ,  return_sequences=True ));\n",
    "                k.add(LSTM(units=160, activation='relu'))\n",
    "                k.add(Dense(units=160, activation='relu'));\n",
    "                k.add(Dense(Model._D_Y_SHAPE[1]));\n",
    "                k.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "        elif (Build == '4'):\n",
    "            #these are common layers for ker.4\n",
    "            k.add(LSTM(units=80, activation='relu', input_shape=(Model._D_X_SHAPE[1],Model._D_X_SHAPE[2]) ,  return_sequences=True ));\n",
    "            k.add(LSTM(units=160, activation='relu'))\n",
    "            k.add(Dense(units=160, activation='relu'));\n",
    "            k.add(Dense(Model._D_Y_SHAPE[1], activation='sigmoid'));\n",
    "            \n",
    "            if (Make == '1'):\n",
    "                k.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '2'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'binary_accuracy'])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '3'):\n",
    "                k.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy', 'binary_accuracy'])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '4'):\n",
    "                k.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '5'):\n",
    "                k.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '6'):\n",
    "                k.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=[kr.metrics.Recall(top_k=20, name='recall_top20')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '7'):\n",
    "                k.add(Dense(Model._D_Y_SHAPE[1], activation='sigmoid'));\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Precision(top_k=20, name='precision_top20')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '8'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Recall(top_k=15, name='recall_top15')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '9'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Precision(top_k=15, name='precision_top15')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '10'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Recall(top_k=10, name='recall_top10')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '11'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Precision(top_k=10, name='precision_top10')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '12'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Recall(name='recall')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '13'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[kr.metrics.Precision(name='precision')])\n",
    "                #when u increase batchsize, decrease learning rate, so it learn slowly, takes small step \n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "        \n",
    "        elif (Build == '5'): #experimentation, will use custom functions\n",
    "            # these are common layers for ker.5. We will revise compile layer for various makes\n",
    "            k.add(LSTM(units=80, activation='relu', input_shape=(Model._D_X_SHAPE[1],Model._D_X_SHAPE[2]) ,  return_sequences=True ));\n",
    "            k.add(LSTM(units=160, activation='relu'))\n",
    "            k.add(Dense(units=160, activation='relu'));\n",
    "            k.add(Dense(Model._D_Y_SHAPE[1], activation='sigmoid'));\n",
    "            \n",
    "            if (Make == '1'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.recall_a])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '2'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.precision_a])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '3'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.f1_score_a])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '4'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.recall_b])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '5'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.precision_b])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '6'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.f1_score_b])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '7'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.recall_c])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '8'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.precision_c])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "            elif (Make == '9'):\n",
    "                k.compile(optimizer='adam', loss='binary_crossentropy', metrics=[cf_metrics.f1_score_c])\n",
    "                print(\"[KER_Model_loader: loaded new build {0}.{1}]\".format(Build, Make))\n",
    "        \n",
    "        Model._M = k;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
