{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/medikid/ai_lotto/blob/master/notebooks/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_faJdu-MIYpM"
   },
   "source": [
    "## **Initiate Collab Notebook and setup Google Drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBdFdcifYdxv"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "QUZLPAzg_vMn",
    "outputId": "91e1f164-db5c-43bc-ef31-40ad80e64a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/g_drive; to attempt to forcibly remount, call drive.mount(\"/content/g_drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#init colab notebooks\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/g_drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1k0iQXOSha1f"
   },
   "outputs": [],
   "source": [
    "!mkdir my_drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ub1HZaRedazy",
    "outputId": "2263bf63-ac01-4abe-c5b3-a1d62e31e5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/content/my_drive/Colab': File exists\n"
     ]
    }
   ],
   "source": [
    "!ln -s \"/content/g_drive/My Drive/Colab\" \"/content/my_drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_lhfdVWHURF6",
    "outputId": "97b0a425-7ccb-4399-961a-476b7de09191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/g_drive/My Drive/Colab/Datascience/ai_lotto/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd \"/content/my_drive/Colab/Datascience/ai_lotto/notebooks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDS-K0xGZSNb"
   },
   "source": [
    "## Github Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "UWfQrIv8n7Fb",
    "outputId": "7018db93-192d-47b1-aa74-09968a3bf41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 12 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (12/12), done.\n",
      "From https://github.com/medikid/ai_lotto\n",
      "   a082cb4..3a1123d  master     -> origin/master\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'root@30da233e8d56.(none)')\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/medikid/ai_lotto.git\n",
    "#!git fetch --all\n",
    "#!git reset --hard origin/master\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "colab_type": "code",
    "id": "XbGqM5_oOLrQ",
    "outputId": "76a8a4d3-85e7-4a3f-e1a2-eddad43a6750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 8 commits.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   ../.gitignore\u001b[m\n",
      "\t\u001b[31mmodified:   ../.ipynb_checkpoints/init-checkpoint.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../.ipynb_checkpoints/requirements-checkpoint.txt\u001b[m\n",
      "\t\u001b[31mmodified:   ../init.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   playground.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../requirements.txt\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31m../__init__.py\u001b[m\n",
      "\t\u001b[31m../idata.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'root@30da233e8d56.(none)')\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "#!git config --global user.email \"soma.programmer@gmail.com\"\n",
    "#!git config --global user.name \"medikid\"\n",
    "\n",
    "#!git config --global user.token '033917f75f24d39c965869d2ea6f261da16f87a1'\n",
    "#!git remote add origin https://medikid:lubdub123$$@github.com/medikid/ai_lotto.git\n",
    "#!git remote add origin https://medikid:033917f75f24d39c965869d2ea6f261da16f87a1@github.com/medikid/ai_lotto.git\n",
    "#!git remote add origin https://033917f75f24d39c965869d2ea6f261da16f87a1:x-oauth-basic@github.com/medikid/ai_lotto.git\n",
    "\n",
    "#!git remote set-url origin https://github.com/medikid/ai_lotto.git\n",
    "\n",
    "!git status\n",
    "!git add -A .\n",
    "!git commit -m \"Cleaned Colab Playgroud file\"\n",
    "\n",
    "\n",
    "!git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0YDo8S6lNMY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uPJSKlxjTq7h",
    "outputId": "043d82a8-94ab-4709-e2aa-1b2a6e2d7dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r 'requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSiSJRZsgJ2s"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTGj4TiYA56S"
   },
   "source": [
    "# lists all classes in the order of loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmVBMKgqA56U"
   },
   "source": [
    "## Class iFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDnZ7hD5A56V"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class iFile:\n",
    "    _FILE = None;\n",
    "    _FILE_PATH=None;\n",
    "    _FILE_NAME=None;\n",
    "    _FILE_NAME_DECIPHERS={};\n",
    "    _FILE_FORMAT=None;\n",
    "    _FILE_TYPE=None;\n",
    "    _FOLDERS_DECIPHERS={};\n",
    "    _FOLDER_PATH=None; #\n",
    "    _ROOT_FOLDER='../';\n",
    "    _FULL_PATH = None; #[../][data/hotspot][/x5/25k][models][ker/1][hotspot_ker_1_2020040320300.h5]\n",
    "    \n",
    "    _GAME_PATH = None;\n",
    "    _DATASET_PATH = None    \n",
    "    _FOLDER_TYPE=None;\n",
    "    \n",
    "    \n",
    "    _INFO = {};\n",
    "\n",
    "    def __init__(self, FileName, FolderPath='', FileFormat=None):\n",
    "        self._FILE_NAME = FileName;\n",
    "        self._FOLDER_PATH = FolderPath;\n",
    "        self._FILE_FORMAT = FileFormat;\n",
    "        self.decipher_file_name();\n",
    "        #self.derive_file_path();\n",
    "        #self.derive_full_path();\n",
    "        print(\"[iFile:__init__]\")\n",
    "        \n",
    "    def set_root_folder(self, RootFolder):\n",
    "        self._ROOT_FOLDER = RootFolder;\n",
    "        print(\"[iFile:set_root_folder] {0}\".format(RootFolder))\n",
    "        \n",
    "    def decipher_file_name(self, delimiter=\"_\"):\n",
    "        print(\"[iFile:decipher_file_name] Not Implemented\");\n",
    "        \n",
    "    def derive_game_path(self, DatasetInfo):\n",
    "        self._GAME_PATH = 'data/' + DatasetInfo['GAME'] + \"/\";\n",
    "        \n",
    "    def derive_dataset_path(self, DatasetInfo):\n",
    "        self._DATASET_PATH = DatasetInfo['xnINPUTS']  + \"/\" + DatasetInfo['xnDRAWS'] + \"/\";\n",
    "        \n",
    "        \n",
    "    def derive_folder_path(self, DatasetInfo):\n",
    "        self.derive_game_path(DatasetInfo);\n",
    "        self.derive_dataset_path(DatasetInfo)\n",
    "        self._FOLDER_PATH = self._GAME_PATH + self._DATASET_PATH;\n",
    "        print(\"[iFile:derive_folder_path] {0}\".format(self._FOLDER_PATH))\n",
    "       \n",
    "   \n",
    "    def set_file_format(self, FileName):\n",
    "        #split name and see if file format is included\n",
    "        Fs=FileName.split(\".\");\n",
    "        try:\n",
    "          self._FILE_FORMAT=Fs[1];\n",
    "        except IndexError:\n",
    "          print(\"File format not included in FIle Name\")\n",
    "        \n",
    "        print(\"[iFile:set_file_format] {0}\".format(self._FILE_FORMAT))\n",
    "        return self._FILE_FORMAT;\n",
    "    \n",
    "   \n",
    "    def derive_file_path(self):\n",
    "        #derive file name from decipher  \n",
    "        print(\"[iFile:derive_file_path] Not Implemented\")\n",
    "\n",
    "    def derive_full_path(self):\n",
    "        FullPath = self._ROOT_FOLDER; #back to /\n",
    "        FullPath += self._FOLDER_PATH; #derived from id\n",
    "        FullPath += self._FILE_PATH;\n",
    "        self._FULL_PATH = FullPath;\n",
    "        \n",
    "        self.ensure_dirs(); #ensure Full Path exists        \n",
    "        print(\"[ifile:derive_full_path] {0}\".format(self._FULL_PATH))\n",
    "        \n",
    "    def get_full_path(self):\n",
    "        print(\"[iFile:get_full_path] {0}\".format(self.__FULL_PATH))\n",
    "        return self._FULL_PATH;\n",
    "    \n",
    "    def ensure_dirs(self):\n",
    "        path = Path(self._FULL_PATH)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def getVarType(self, Var):\n",
    "        varType = ''\n",
    "        if (type(Var) == pd.core.frame.DataFrame):\n",
    "            varType = \"Dataframe\";\n",
    "        elif (type(Var) == type(None)):\n",
    "            varType = \"Nonetype\";\n",
    "        elif (type(Var) == np.ndarray):\n",
    "            varType = \"NumpyArray\";\n",
    "        #elif(type(df) == np.)\n",
    "        \n",
    "        return varType;\n",
    "        \n",
    "    def isDataframe(self, Var):\n",
    "        return self.getVarType(Var) == \"Dataframe\";\n",
    "    \n",
    "    def isNonetype(self, Var):\n",
    "        return self.getVarType(Var) == \"Nonetype\";\n",
    "    \n",
    "    def isNumpyArray(self, Var):\n",
    "        return self.getVarType(Var) == \"NumpyArray\";\n",
    "    \n",
    "    def print_file_info(self):\n",
    "        print(\"FILE NAME: {0}\".format(self._FILE_NAME));\n",
    "        print(\"FILE FORMAT(type): {0}[{1}]\".format(self._FILE_FORMAT, self._FILE_TYPE));\n",
    "        print(\"FILE PATH: {0}\".format(self._FILE_PATH));\n",
    "        print(\"FILE NAME PARTS: {0}\".format(self._INFO));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcoR7sK1A56c"
   },
   "source": [
    "## Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "b4PuQyP8A56d",
    "outputId": "75251067-3cca-491c-b9c1-304e3c3c4626"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sb\n",
    "import keras as kr\n",
    "from numpy import array\n",
    "from ipynb.fs.full.ifile import iFile\n",
    "\n",
    "class Data(iFile):\n",
    "    _FILE_FORMAT = \"pkl\"\n",
    "    _DATA_FOLDER = None;\n",
    "    _DF_MASTER = None\n",
    "    _DF_IDs = None;\n",
    "    _DF_R = None;\n",
    "    _DF_DR = None;\n",
    "    _DF_DP = None;\n",
    "    _NPZ_MASTER = None\n",
    "    _MIN_ID=0;\n",
    "    _MAX_ID=0;\n",
    "    _COUNT_ID=0;\n",
    "    \n",
    "    def __init__(self, MasterFileName=\"hotspot_master\", LoadMaster=False, DataFolder=\"data/\"):\n",
    "        self._FILE_NAME  = MasterFileName;\n",
    "        self._DATA_FOLDER = DataFolder;\n",
    "        super().__init__(MasterFileName, DataFolder, self._FILE_FORMAT);\n",
    "        \n",
    "        self.derive_folder_path();\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "        \n",
    "        if(LoadMaster == True):\n",
    "            self.load_master_df();\n",
    "            self.deconstruct_master_df()\n",
    "            print(\"Loaded data file %s\" %(self._FULL_PATH))\n",
    "            \n",
    "    #v\n",
    "    def decipher_file_name(self, Delimiter=\"_\"):\n",
    "        #if .format is included, remove this first\n",
    "        \n",
    "        FN_PARTS = self._FILE_NAME.split(Delimiter);\n",
    "        try:\n",
    "            self._INFO['GAME'], self._GAME = FN_PARTS[0], FN_PARTS[0]\n",
    "            self._INFO['FOLDER_TYPE'], self._FOLDER_TYPE = FN_PARTS[1], FN_PARTS[1]\n",
    "            self._INFO['DATA_TYPE'], self._DATA_TYPE = FN_PARTS[2], FN_PARTS[2]\n",
    "            #check if file format\n",
    "            self.set_file_format(self._FILE_NAME)\n",
    "        except IndexError:\n",
    "            pass;      \n",
    "        \n",
    "    def derive_folder_path(self):\n",
    "        self._FOLDER_PATH = 'data/' + self._GAME + \"/\";\n",
    "        \n",
    "    def derive_file_path(self):\n",
    "        self._FILE_PATH = \"master\" + \"/\" + self._FILE_NAME +\".\" + self._FILE_FORMAT;\n",
    "    \n",
    "    #v    \n",
    "    def load_file(self):\n",
    "        self.set_master_df(pd.read_pickle(self._FULL_PATH));   \n",
    "\n",
    "            \n",
    "    def get_data_folder(self):\n",
    "        return self._DATA_FOLDER;\n",
    "    \n",
    "    def load_master_df(self):\n",
    "        if (self._FILE_NAME != \"\"):\n",
    "            self.set_master_df(pd.read_pickle(self._FULL_PATH));\n",
    "    \n",
    "    def set_master_df(self, master_df):\n",
    "        self._DF_MASTER = master_df;\n",
    "        self._MIN_ID = self._DF_MASTER.min();\n",
    "        self._MAX_ID = self._DF_MASTER.index.max();\n",
    "        self._COUNT_ID = self._DF_MASTER.shape[0];\n",
    "        \n",
    "    def get_master_df(self):\n",
    "        return self._DF_MASTER;\n",
    "    \n",
    "    def set_master_npz(self, master_npz):\n",
    "        self._NPZ_MASTER = master_df;\n",
    "        \n",
    "    def get_master_npz(self):\n",
    "        return self._NPZ_MASTER\n",
    "    \n",
    "    def get_result_columns(self):\n",
    "        i=1; r=[];\n",
    "        while(i<=20):\n",
    "            r.append('r'+str(i));\n",
    "            i+=1;        \n",
    "        return r;\n",
    "    \n",
    "    def get_draw_columns(self):\n",
    "        i=1; drs=[];\n",
    "        while(i<=80):\n",
    "            drs.append('dr'+str(i));\n",
    "            i+=1;        \n",
    "        return drs;\n",
    "    \n",
    "    def get_depth_columns(self):\n",
    "        i=1; dps=[];\n",
    "        while(i<=80):\n",
    "            dps.append('dp'+str(i));\n",
    "            i+=1;        \n",
    "        return dps;\n",
    "    \n",
    "    def get_count_id(self, df=None):\n",
    "        if(df is None):\n",
    "            count_id = self._COUNT_ID;\n",
    "        else:\n",
    "            count_id = df.shape[0];\n",
    "        return count_id;\n",
    "    \n",
    "    def get_first_id(self, df=None):\n",
    "        if(df is None):\n",
    "            min_id = self._MIN_ID;\n",
    "        else:\n",
    "            min_id = df[:1].index.item();\n",
    "        return min_id;\n",
    "    \n",
    "    def get_last_id(self, df=None):\n",
    "        if(df is None):\n",
    "            max_id = self._MAX_ID;\n",
    "        else:\n",
    "            max_id = df[-1:].index.item();\n",
    "        return max_id;\n",
    "    \n",
    "    def deconstruct_master_df(self):\n",
    "        if(self._DF_IDs is None):\n",
    "            self._DF_IDs, self._DF_R, self._DF_DR, self._DF_DP = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame();\n",
    "\n",
    "            if (self._DF_MASTER is not None ): #or self._DF_MASTER.empty): #empty is an attribute, not a function\n",
    "                print(\"ERROR: Missing Master Dataframe\");\n",
    "            else:\n",
    "                self._DF_IDs = pd.DataFrame(self._DF_MASTER.index);\n",
    "                self._DF_R = self._DF_MASTER.loc[:,self.get_result_columns()]\n",
    "                self._DF_DR = self._DF_MASTER.loc[:,self.get_draw_columns()]\n",
    "                self._DF_DP = self._DF_MASTER.loc[:,self.get_depth_columns()]\n",
    "\n",
    "            return self._DF_IDs, self._DF_R, self._DF_DR, self._DF_DP;\n",
    "    \n",
    "    def df2np(self, df):\n",
    "        if(isinstance(df, pd.DataFrame)):\n",
    "            df = df.to_numpy();\n",
    "        return df;\n",
    "    \n",
    "    def np2df(self, nparray):\n",
    "        if(isinstance(nparray, np.ndarray)):\n",
    "            nparray = pd.DataFrame(nparray);\n",
    "        return nparray;\n",
    "            \n",
    "    def split_xy(self, df):\n",
    "        x, y = pd.DataFrame(), pd.DataFrame();\n",
    "        if not df.empty:\n",
    "           x, y = df[:-1],df[1:];\n",
    "        else:\n",
    "            print(\"Empty dataframe\")\n",
    "        return x,y;\n",
    "        \n",
    "    def print_xy(self, x, y):\n",
    "        x = self.df2np(x);\n",
    "        y= self.df2np(y)\n",
    "        for i in range(len(x)):\n",
    "            print(x[i],y[i])\n",
    "            \n",
    "    def print_xy_prediction(self, y_hat, y_test):\n",
    "        print(\"[Predicted vs Actuual]\")\n",
    "        \n",
    "        #n_input - input rows- number of previous input timesteps t,t-1,t-2,t....n\n",
    "        #t_output - Y timesteps to predict. 0 by default - predicts t+1        \n",
    "    def to_supervised(self, data_df, n_input, t_output=0):\n",
    "        data = self.df2np(data_df);\n",
    "        X, y = list(), list()\n",
    "        ix_start = 0\n",
    "        # step over the entire history one time step at a time\n",
    "        for i in range(len(data)):\n",
    "            # define the end of the input sequence\n",
    "            ix_end = ix_start + n_input\n",
    "            ix_output = ix_end + t_output\n",
    "            # ensure we have enough data for this instance\n",
    "            if ix_output < len(data):\n",
    "                X.append(data[ix_start:ix_end])\n",
    "                y.append(data[ix_output])\n",
    "                # move along one time step\n",
    "                ix_start += 1\n",
    "        return array(X), array(y);\n",
    "    \n",
    "    def create_supervised_package(self, masterDF, startID, nDraws, nInputs, nTests):\n",
    "        #ids, X, Y, X_test, Y_test = np.ndarray([]), np.ndarray([]), np.ndarray([]), np.ndarray([]), np.ndarray([]);\n",
    "        cutOff = nDraws + nInputs + nTests;\n",
    "        nDFs = masterDF[startID:cutOff]\n",
    "        nIDs = self.df2np(pd.DataFrame(nDFs.index))\n",
    "        X_all, Y_all = self.to_supervised(nDFs,nInputs)\n",
    "        \n",
    "        CutSplit = -nTests; #split by 5, uses [:-5] and [-5:]\n",
    "        X, Y, X_test, Y_test = self.xy_split(X_all, Y_all, CutSplit);\n",
    "        IDs, IDs_test =  nIDs[nInputs:CutSplit], nIDs[CutSplit:];\n",
    "        return IDs, X, Y, IDs_test, X_test, Y_test\n",
    "        \n",
    "        \n",
    "    def xy_split(self, X_all, Y_all, CutSplit):\n",
    "        x,y,x_test,y_test = X_all[:CutSplit], Y_all[:CutSplit], X_all[CutSplit:], Y_all[CutSplit:];\n",
    "        return x, y, x_test, y_test;\n",
    "    \n",
    "    def create_new(self, newMasterFile, newMasterDF):\n",
    "        self._FILE_NAME = newMasterFile;\n",
    "        self.derive_folder_path();\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "        \n",
    "        newMasterDF.to_pickle(self._FULL_PATH)\n",
    "        print(\"Saved new file {0}\".format(self._FULL_PATH))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QKbqaR2iA56i"
   },
   "source": [
    "## Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtuHHN_rA56j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ipynb.fs.full.ifile import iFile\n",
    "from ipynb.fs.full.idata import Data\n",
    "\n",
    "class Dataset(iFile):\n",
    "    _ID = None;\n",
    "    _GAME=None\n",
    "    _D = None;\n",
    "    _DATASET_PATH = None;\n",
    "    _FOLDER_TYPE = 'datasets'\n",
    "    _DF_MASTER = None;\n",
    "    \n",
    "    def __init__(self, DatasetID='', FolderPath= 'data/', FileFormat='npz'):\n",
    "        self._ID = DatasetID;\n",
    "        super().__init__(DatasetID, FolderPath, FileFormat)\n",
    "        self.decipher_file_name();\n",
    "        self.derive_folder_path(self._INFO); #you don't need this for model\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "    \n",
    "    def decipher_file_name(self, delimiter=\"_\"):\n",
    "        #if .format is included, remove this first\n",
    "        FN = self._FILE_NAME\n",
    "        FN_PARTS = FN.split(delimiter);\n",
    "        self._INFO['GAME'], self._GAME = FN_PARTS[0], FN_PARTS[0]\n",
    "        self._INFO['xnINPUTS'] = FN_PARTS[1]\n",
    "        self._INFO['nINPUTS'] = self.derive_xninputs(self._INFO['xnINPUTS'])\n",
    "        self._INFO['xnDRAWS'] = FN_PARTS[2]\n",
    "        self._INFO['nDRAWS'] = self.derive_xndraws(self._INFO['xnDRAWS'])\n",
    "        self._INFO['DATA_TYPE'] = FN_PARTS[3] \n",
    "        #check if file format\n",
    "        #self.set_file_format(self._FILE_NAME); #can't use this as we use decimal\n",
    "\n",
    "        return self._FILE_NAME_DECIPHERS;\n",
    "    \n",
    "    #25000=>25k and 25k=>25000\n",
    "    def derive_xndraws(self, xndraws):\n",
    "        nDraw = 0; notation=''\n",
    "        if (type(xndraws) == str):\n",
    "            notation=xndraws[len(xndraws)-1];            \n",
    "            if(type(notation) == int): multiple = 1;\n",
    "            elif (notation=='k'): multiple = 1000;\n",
    "            elif (notation=='m'): multiple = 1000000;\n",
    "            new_st = float(xndraws.replace(notation,''))# change to float 2.5 first\n",
    "            nDraw = int(new_st*multiple) #then covert back to int from float\n",
    "            print(\"xndraw{0}, new_st{1}, multiple{2}, notation{3}\".format(xndraws, new_st, multiple, notation))\n",
    "        elif (type(xndraws) == int):\n",
    "            if(xndraws > 1000000) :\n",
    "                notation = 'm';\n",
    "                nDraw = str(xndraws//1000000)+notation;\n",
    "            elif (xndraws > 1000):\n",
    "                notation = 'k';\n",
    "                nDraw = str(xndraws//1000)+notation;\n",
    "            else:\n",
    "                nDraw = str(xndraws//1);\n",
    "        return nDraw;\n",
    "    \n",
    "    #x15=>15 and 15=>x15\n",
    "    def derive_xninputs(self, xnInputs):\n",
    "        nInputs = 0;\n",
    "        if (type(xnInputs) == str):\n",
    "            #remove first character\n",
    "            nInputs = int(xnInputs[1:]);\n",
    "        elif (type(xnInputs) == int):\n",
    "            nInputs = 'x'+str(xnInputs);        \n",
    "        return nInputs;\n",
    "    \n",
    "\n",
    "    def set_file_format(self, FileName):\n",
    "        #split name and see if file format is included\n",
    "        Fs=FileName.split(\".\");\n",
    "        try:\n",
    "          self._FILE_FORMAT=Fs[1];\n",
    "        except IndexError:\n",
    "          print(\"File format not included in FIle Name\")\n",
    "        return self._FILE_FORMAT;\n",
    "\n",
    "    def derive_file_path(self):\n",
    "        #derive file name from decipher  \n",
    "        FilePath = self._FOLDER_TYPE + '/';\n",
    "        FilePath += self._FILE_NAME;\n",
    "        FilePath += \".\" + self._FILE_FORMAT;\n",
    "        self._FILE_PATH = FilePath;\n",
    "        print(\"[iDataset:derive_file_path] {0}\".format(self._FILE_PATH))\n",
    "        \n",
    "    def load(self):\n",
    "        self._D = np.load(self._FULL_PATH)\n",
    "        print(\"Loading dataset {0}\".format(self._FULL_PATH))\n",
    "        \n",
    "    def load_master_df(self):\n",
    "        if(self._DF_MASTER is None):\n",
    "            masterPkl = self._GAME +\"_master\";\n",
    "            masterDF = Data(masterPkl);\n",
    "            self._DF_MASTER = masterDF._DF_MASTER;\n",
    "            print(\"[iDataset:load_master_df] Loaded master DF\")\n",
    "            \n",
    "    def derive_full_path_by_id(self, newDatasetID):\n",
    "        self._FILE_NAME = newDatasetID; #this is the onlyl thing you need to change\n",
    "        self.decipher_file_name();\n",
    "        self.derive_folder_path(self._INFO); #you don't need this for model\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();        \n",
    "        self.ensure_dirs(); #ensure Full Path exists\n",
    "        \n",
    "    def create_new_by_id(self, DF_Master, newDatasetID, nTests=15):\n",
    "        self.derive_full_path_by_id(newDatasetID);        \n",
    "        #now use file info details self._INFO\n",
    "        \n",
    "        masterPkl = self._INFO['GAME'] +\"_master\";\n",
    "        masterData = Data(masterPkl);\n",
    "        ids, x, y, ids_test, x_test, y_test=masterData.create_supervised_package(DF_Master, 0, self._INFO['nDRAWS'], self._INFO['nINPUTS'], nTests);\n",
    "        \n",
    "        np.savez(self._FULL_PATH, IDs=ids, X=x, Y=y, IDs_test=ids_test, X_test=x_test, Y_test=y_test);\n",
    "        \n",
    "        print(\"Saved new datast file {0}\".format(self._FULL_PATH))\n",
    "        \n",
    "    def derive_new_dataset_id(self, Game, nDraws, nInputs, DataType='dr'):\n",
    "        newDatasetID = Game + \"_\";\n",
    "        newDatasetID += self.derive_xninputs(nInputs) + \"_\";\n",
    "        newDatasetID += self.derive_xndraws(nDraws) + \"_\";\n",
    "        newDatasetID += DataType;\n",
    "        return newDatasetID;\n",
    "        \n",
    "    def create_new(self, DF_Master, startID, nDraws, nInputs, nTests=15, DataType='dr'):        \n",
    "        newDatasetID = self.derive_new_dataset_id(self._INFO['GAME'], nDraws, nInputs, DataType);\n",
    "        \n",
    "        self.create_new_by_id(DF_Master, newDatasetID, nTests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWTsUKIzA56p"
   },
   "source": [
    "## Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MT_k9qVUA56q"
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.full.ifile import iFile\n",
    "\n",
    "class Model(iFile):\n",
    "    _M=None;\n",
    "    _ID=None;\n",
    "    _GAME=None;\n",
    "    _API = None;\n",
    "    _BUILD = None;\n",
    "    _VERSION = None;\n",
    "    \n",
    "    #set default model\n",
    "    _FOLDER_TYPE = 'models'\n",
    "    _FOLDER_PATH = None;\n",
    "    _FILE_FORMAT = None\n",
    "    \n",
    "    def __init__(self, ModelID, Dataset, FileFormat='h5'):\n",
    "        self._ID = ModelID;\n",
    "        super().__init__(ModelID, Dataset._FOLDER_PATH, FileFormat);\n",
    "        self.decipher_file_name();\n",
    "        \n",
    "        #we are not deriving folder_path, but using dataset folder\n",
    "           \n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "        print(\"[iModel:__init__\")\n",
    "        \n",
    "    def set_decipher_info(self):\n",
    "        self._INFO['GAME'] = self._GAME;\n",
    "        self._INFO['API'] = self._API;\n",
    "        self._INFO['BUILD'] = self._BUILD;\n",
    "        self._INFO['VERSION'] = self._VERSION;\n",
    "        print(\"[iModel:set_decipher_info] {0}\".format(self._INFO))\n",
    "        \n",
    "    def decipher_file_name(self, Delimiter=\".\"):        \n",
    "        ids = self._FILE_NAME.split(Delimiter);\n",
    "        try:\n",
    "            self._GAME = ids[0]\n",
    "            self._API = ids[1]\n",
    "            self._BUILD = ids[2]\n",
    "            self._VERSION = ids[3]\n",
    "        except IndexError:\n",
    "            self.LoadBestVersion();\n",
    "        \n",
    "        print(\"[iModel:decipher_file_name]\")\n",
    "        \n",
    "        self.set_decipher_info();        \n",
    "    \n",
    "    def derive_game_path(self):\n",
    "        self._GAME_PATH = self._INFO['GAME']\n",
    "        \n",
    "            \n",
    "    def derive_file_path(self):\n",
    "        #derive file name from decipher  \n",
    "        #FilePath = self._FOLDER_PATH;\n",
    "        FilePath = self._FOLDER_TYPE + \"/\";\n",
    "        FilePath += self._INFO['API'] + \"/\";\n",
    "        FilePath += self._INFO['BUILD'] + \"/\";\n",
    "        #FilePath += \"/\" + self._INFO['VERSION'];\n",
    "        FilePath += self._FILE_NAME;\n",
    "        FilePath += \".\" + self._FILE_FORMAT;\n",
    "        self._FILE_PATH = FilePath;\n",
    "        print(\"[iModel:derive_file_path] {0}\".format(self._FILE_PATH))\n",
    "        \n",
    "    \n",
    "    def load(self):\n",
    "        print(\"[iModel:load] Not Implemented\")\n",
    "        pass;\n",
    "    \n",
    "    def load_best_version(self):\n",
    "        print(\"[iModel:load_best_version] Not Implemented\")\n",
    "        pass;\n",
    "    \n",
    "    def load_latest_version(self):\n",
    "        print(\"[iModel:load_latest_version] Not Implemented\")\n",
    "        pass;\n",
    "           \n",
    "             \n",
    "    def get_model_summary(self):\n",
    "        return self._M.summary();\n",
    "    \n",
    "    def train(self, x, y, BatchSize=32, Epochs=1000):\n",
    "        self._M.fit(x, y, batch_size=BatchSize, epochs=Epochs);        \n",
    "        pass;\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return y_hat;\n",
    "    \n",
    "    def save(self):\n",
    "        self._M.save(self._FULL_PATH)\n",
    "        \n",
    "    def print_summary(self):\n",
    "        print(self._M.summary())\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxOX1aFoA56v"
   },
   "source": [
    "## Class KER_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YPRzo4uA56x"
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.full.imodel import Model\n",
    "import keras as kr\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class KER_Model(Model):\n",
    "    _MODEL_PATH = None;\n",
    "    \n",
    "    def __init__(self, ModelID, Dataset):\n",
    "        super().__init__(ModelID, Dataset)\n",
    "        self._MODEL_PATH = self._FULL_PATH;\n",
    "        print(\"[KER_Model:__init__]\")\n",
    " \n",
    "    def load(self):\n",
    "        self._M = load_model(self._FULL_PATH)\n",
    "        print(\"[KER_Model:load]: Loading {0}\".format(self._FULL_PATH))\n",
    "        pass;\n",
    "    \n",
    "    def save(self):\n",
    "        self._M.save(self._FULL_PATH)\n",
    "        print(\"[KER_Model:save]: Saving {0}\".format(self._FULL_PATH))\n",
    "    \n",
    "    def load_best_version(self):\n",
    "        pass;\n",
    "    \n",
    "    def load_latest_version(self):\n",
    "        pass;\n",
    "    \n",
    "    def predict(self, X_test, isBatch=True):\n",
    "        Y_hat = np.array()\n",
    "        if(isBatch == True):\n",
    "            Y_hat = self._M.predict_on_batch(X_test);\n",
    "        else:\n",
    "            Y_hat = self._M.predict(X_test);\n",
    "            \n",
    "        return Y_hat;     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EiJYpkNKA562"
   },
   "source": [
    "## Class TFL_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtjaeIuZA563"
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.full.imodel import Model\n",
    "import tensorflow as tfl\n",
    "\n",
    "class TFL_Model(Model):\n",
    "    _MODEL_PATH = None;\n",
    "    \n",
    "    def __init__(self, ModelID, Dataset):\n",
    "        super().__init__(ModelID, Dataset)\n",
    " \n",
    "    def load(self):\n",
    "        print(\"Loading {0}\".format(self._FULL_PATH))\n",
    "        pass;\n",
    "    \n",
    "    def save(self):\n",
    "        print(\"Saving {0}\".format(self._FULL_PATH))\n",
    "    \n",
    "    def load_best_version(self):\n",
    "        pass;\n",
    "    \n",
    "    def load_latest_version(self):\n",
    "        pass;\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFB-eBE3A568"
   },
   "source": [
    "## Class AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tw_sHcBMA569"
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.full.ker_model import KER_Model;\n",
    "from ipynb.fs.full.tfl_model import TFL_Model;\n",
    "from ipynb.fs.full.idataset import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class AI:\n",
    "    _MODEL =None;\n",
    "    _DATASET =None;\n",
    "    _MASTER=None;\n",
    "    _GAME = None;\n",
    "    _API = None;\n",
    "    \n",
    "    def __init__(self, ModelID, DatasetID):\n",
    "        self.load_dataset(DatasetID)\n",
    "        \n",
    "        self.load_model(ModelID, self._DATASET); #you need x5/25k from datasetfolder\n",
    "        \n",
    "        print(\"[AI:__init__]\")\n",
    "        pass;\n",
    "\n",
    "    \n",
    "    def setup_model(self, ModelName):\n",
    "        pass;\n",
    "    \n",
    "    def load_model(self, ModelID, Dataset):\n",
    "        info = ModelID.split(\".\");\n",
    "        self._GAME = info[0];\n",
    "        self._API = info[1]\n",
    "        \n",
    "        print(\"Game: {0} API {1}\".format(self._GAME, self._API))\n",
    "        \n",
    "        if (self._API == 'ker'):\n",
    "            self._MODEL = KER_Model(ModelID, Dataset);\n",
    "        elif(self._API == 'tfl'):\n",
    "            self._MODEL = TFL_Model(ModelID, Dataset);\n",
    "            \n",
    "        self._MODEL.load();\n",
    "        print(\"Loaded Model {0}\".format(self._MODEL._FULL_PATH))\n",
    "    \n",
    "    def load_dataset(self, DatasetName):\n",
    "        self._DATASET = Dataset(DatasetName); \n",
    "        self._DATASET.load();\n",
    "        #Dataset is stored in self._D._DATASET[IDs,X,Y,IDs_test,X_test,Y_test]\n",
    "        print(\"Loaded Dataset {0}\".format(self._DATASET._FULL_PATH))\n",
    "    \n",
    "    def save_model(self):\n",
    "        self._MODEL.save(self._FULL_PATH)\n",
    "        pass;\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        pass;\n",
    "    \n",
    "    def train_model(self):\n",
    "        pass;\n",
    "    \n",
    "    def predict_model(self, X_test, IsBatch=True):\n",
    "        Y_hat = self._MODEL.predict(X_test, IsBatch)\n",
    "        return Y_hat;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDGSqErkA57E"
   },
   "source": [
    "## Class Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "Jk9g5c8LA57F",
    "outputId": "63b761d2-d443-4d69-8157-c93e1d7f9b2b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-75661ff2bf47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_GAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'keno'\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipynb'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare master data. First load all master files\n",
    "from ipynb.fs.full.idata import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "_GAME = 'keno';  \n",
    "Dataframes={}; _DATA_TYPE = 'dr'; _xnINPUTS=15; xnDRAWS='2.528m'; _TESTS=15;\n",
    "_API = 'KER'; _BUILD = '1'; _VERSION='1';\n",
    "Dataframes[\"DF_{0}\".format(_DATA_TYPE).upper()] = pd.read_pickle(\"../data/{0}/master/{0}_master_{1}.pkl\".format(_GAME, _DATA_TYPE))\n",
    "Dataframes['DF_DR']\n",
    "\n",
    "#pull some valid dataset to initiate empty datset\n",
    "datasetID = \"{0}_{1}_{2}_{3}\".format(_GAME,_xnINPUTS,_xnDRAWS,_DATA_TYPE)\n",
    "D = Dataset(datasetID)\n",
    "\n",
    "new_dataset_id = \"{0}_{1}_{2}_{3}\".format(_GAME,_xnINPUTS,_xnDRAWS,_DATA_TYPE)\n",
    "D.create_new_by_id(Dataframes['DF_DR'], new_dataset_id, _TESTS);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaGSqRHkA57J"
   },
   "source": [
    "## Class Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pX9l2CT3A57K"
   },
   "outputs": [],
   "source": [
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "#----------------------------------------------------\n",
    "#_GAME = 'keno';  \n",
    "# _xnINPUTS='x15';_xnDRAWS='2.528m';_DATA_TYPE = 'dr'; \n",
    "#_API = 'KER'; _BUILD = '1'; _VERSION='1';\n",
    "datasetID = 'keno_x15_2.528m_dr'           #\"{0}_{1}_{2}_{3}\".format(_GAME,_xnINPUTS,_xnDRAWS,_DATA_TYPE)\n",
    "modelID = 'keno.ker.2.1'             #\"{0}.{1}.{2}.{3}\".format(_GAME,_API,_BUILD, _VERSION)\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "d = Dataset(datasetID)\n",
    "d.load();\n",
    "dataset = d._DATASET;\n",
    "\n",
    "#Keno.ker.1.1\n",
    "k = KER_Model(modelID, d);\n",
    "k._M = Sequential()\n",
    "k._M.add(LSTM(units=100, activation='relu', input_shape=(dataset['X'].shape[1], dataset['X'].shape[2]) , return_sequences=True ));\n",
    "k._M.add(LSTM(units=100, activation='relu'))\n",
    "k._M.add(Dense(dataset['Y'].shape[1]));\n",
    "k._M.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "k.train(dataset['X'], dataset['Y'])\n",
    "k.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asAoOptxW1l_"
   },
   "outputs": [],
   "source": [
    "## Print tree structure of Data folder\n",
    "#!apt-get install tree\n",
    "!tree '../data/keno'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "playground.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
