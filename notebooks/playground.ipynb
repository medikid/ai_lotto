{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lists all classes in the order of loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class iFile:\n",
    "    _FILE = None;\n",
    "    _FILE_PATH=None;\n",
    "    _FILE_NAME=None;\n",
    "    _FILE_NAME_DECIPHERS={};\n",
    "    _FILE_FORMAT=None;\n",
    "    _FILE_TYPE=None;\n",
    "    _FOLDERS_DECIPHERS={};\n",
    "    _FOLDER_PATH=None; #\n",
    "    _ROOT_FOLDER='../';\n",
    "    _FULL_PATH = None; #[../][data/hotspot][/x5/25k][models][ker/1][hotspot_ker_1_2020040320300.h5]\n",
    "    \n",
    "    _GAME_PATH = None;\n",
    "    _DATASET_PATH = None    \n",
    "    _FOLDER_TYPE=None;\n",
    "    \n",
    "    \n",
    "    _INFO = {};\n",
    "\n",
    "    def __init__(self, FileName, FolderPath='', FileFormat=None):\n",
    "        self._FILE_NAME = FileName;\n",
    "        self._FOLDER_PATH = FolderPath;\n",
    "        self._FILE_FORMAT = FileFormat;\n",
    "        self.decipher_file_name();\n",
    "        #self.derive_file_path();\n",
    "        #self.derive_full_path();\n",
    "        print(\"[iFile:__init__]\")\n",
    "        \n",
    "    def set_root_folder(self, RootFolder):\n",
    "        self._ROOT_FOLDER = RootFolder;\n",
    "        print(\"[iFile:set_root_folder] {0}\".format(RootFolder))\n",
    "        \n",
    "    def decipher_file_name(self, delimiter=\"_\"):\n",
    "        print(\"[iFile:decipher_file_name] Not Implemented\");\n",
    "        \n",
    "    def derive_game_path(self, DatasetInfo):\n",
    "        self._GAME_PATH = 'data/' + DatasetInfo['GAME'] + \"/\";\n",
    "        \n",
    "    def derive_dataset_path(self, DatasetInfo):\n",
    "        self._DATASET_PATH = DatasetInfo['xnINPUTS']  + \"/\" + DatasetInfo['xnDRAWS'] + \"/\";\n",
    "        \n",
    "        \n",
    "    def derive_folder_path(self, DatasetInfo):\n",
    "        self.derive_game_path(DatasetInfo);\n",
    "        self.derive_dataset_path(DatasetInfo)\n",
    "        self._FOLDER_PATH = self._GAME_PATH + self._DATASET_PATH;\n",
    "        print(\"[iFile:derive_folder_path] {0}\".format(self._FOLDER_PATH))\n",
    "       \n",
    "   \n",
    "    def set_file_format(self, FileName):\n",
    "        #split name and see if file format is included\n",
    "        Fs=FileName.split(\".\");\n",
    "        try:\n",
    "          self._FILE_FORMAT=Fs[1];\n",
    "        except IndexError:\n",
    "          print(\"File format not included in FIle Name\")\n",
    "        \n",
    "        print(\"[iFile:set_file_format] {0}\".format(self._FILE_FORMAT))\n",
    "        return self._FILE_FORMAT;\n",
    "    \n",
    "   \n",
    "    def derive_file_path(self):\n",
    "        #derive file name from decipher  \n",
    "        print(\"[iFile:derive_file_path] Not Implemented\")\n",
    "\n",
    "    def derive_full_path(self):\n",
    "        FullPath = self._ROOT_FOLDER; #back to /\n",
    "        FullPath += self._FOLDER_PATH; #derived from id\n",
    "        FullPath += self._FILE_PATH;\n",
    "        self._FULL_PATH = FullPath;\n",
    "        \n",
    "        print(\"[ifile:derive_full_path] {0}\".format(self._FULL_PATH))\n",
    "        \n",
    "    def get_full_path(self):\n",
    "        print(\"[iFile:get_full_path] {0}\".format(self.__FULL_PATH))\n",
    "        return self._FULL_PATH;\n",
    "    \n",
    "    def ensure_dirs(self):\n",
    "        path = Path(self._FULL_PATH)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def getVarType(self, Var):\n",
    "        varType = ''\n",
    "        if (type(Var) == pd.core.frame.DataFrame):\n",
    "            varType = \"Dataframe\";\n",
    "        elif (type(Var) == type(None)):\n",
    "            varType = \"Nonetype\";\n",
    "        elif (type(Var) == np.ndarray):\n",
    "            varType = \"NumpyArray\";\n",
    "        #elif(type(df) == np.)\n",
    "        \n",
    "        return varType;\n",
    "        \n",
    "    def isDataframe(self, Var):\n",
    "        return self.getVarType(Var) == \"Dataframe\";\n",
    "    \n",
    "    def isNonetype(self, Var):\n",
    "        return self.getVarType(Var) == \"Nonetype\";\n",
    "    \n",
    "    def isNumpyArray(self, Var):\n",
    "        return self.getVarType(Var) == \"NumpyArray\";\n",
    "    \n",
    "    def print_file_info(self):\n",
    "        print(\"FILE NAME: {0}\".format(self._FILE_NAME));\n",
    "        print(\"FILE FORMAT(type): {0}[{1}]\".format(self._FILE_FORMAT, self._FILE_TYPE));\n",
    "        print(\"FILE PATH: {0}\".format(self._FILE_PATH));\n",
    "        print(\"FILE NAME PARTS: {0}\".format(self._INFO));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sb\n",
    "import keras as kr\n",
    "from numpy import array\n",
    "#from ipynb.fs.full.ifile import iFile\n",
    "\n",
    "class Data(iFile):\n",
    "    _FILE_FORMAT = \"pkl\"\n",
    "    _DATA_FOLDER = None;\n",
    "    _DF_MASTER = None\n",
    "    _DF_IDs = None;\n",
    "    _DF_R = None;\n",
    "    _DF_DR = None;\n",
    "    _DF_DP = None;\n",
    "    _NPZ_MASTER = None\n",
    "    _MIN_ID=0;\n",
    "    _MAX_ID=0;\n",
    "    _COUNT_ID=0;\n",
    "    \n",
    "    def __init__(self, MasterFileName=\"hotspot_master\", LoadMaster=False, DataFolder=\"data/\"):\n",
    "        self._FILE_NAME  = MasterFileName;\n",
    "        self._DATA_FOLDER = DataFolder;\n",
    "        super().__init__(MasterFileName, DataFolder, self._FILE_FORMAT);\n",
    "        \n",
    "        self.derive_folder_path();\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "        \n",
    "        if(LoadMaster == True):\n",
    "            self.load_master_df();\n",
    "            self.deconstruct_master_df()\n",
    "            print(\"Loaded data file %s\" %(self._FULL_PATH))\n",
    "            \n",
    "    #v\n",
    "    def decipher_file_name(self, Delimiter=\"_\"):\n",
    "        #if .format is included, remove this first\n",
    "        \n",
    "        FN_PARTS = self._FILE_NAME.split(Delimiter);\n",
    "        try:\n",
    "            self._INFO['GAME'], self._GAME = FN_PARTS[0], FN_PARTS[0]\n",
    "            self._INFO['FOLDER_TYPE'], self._FOLDER_TYPE = FN_PARTS[1], FN_PARTS[1]\n",
    "            self._INFO['DATA_TYPE'], self._DATA_TYPE = FN_PARTS[2], FN_PARTS[2]\n",
    "            #check if file format\n",
    "            self.set_file_format(self._FILE_NAME)\n",
    "        except IndexError:\n",
    "            pass;      \n",
    "        \n",
    "    def derive_folder_path(self):\n",
    "        self._FOLDER_PATH = 'data/' + self._GAME + \"/\";\n",
    "        \n",
    "    def derive_file_path(self):\n",
    "        self._FILE_PATH = \"master\" + \"/\" + self._FILE_NAME +\".\" + self._FILE_FORMAT;\n",
    "    \n",
    "    #v    \n",
    "    def load_file(self):\n",
    "        self.set_master_df(pd.read_pickle(self._FULL_PATH));   \n",
    "\n",
    "            \n",
    "    def get_data_folder(self):\n",
    "        return self._DATA_FOLDER;\n",
    "    \n",
    "    def load_master_df(self):\n",
    "        if (self._FILE_NAME != \"\"):\n",
    "            self.set_master_df(pd.read_pickle(self._FULL_PATH));\n",
    "    \n",
    "    def set_master_df(self, master_df):\n",
    "        self._DF_MASTER = master_df;\n",
    "        self._MIN_ID = self._DF_MASTER.min();\n",
    "        self._MAX_ID = self._DF_MASTER.index.max();\n",
    "        self._COUNT_ID = self._DF_MASTER.shape[0];\n",
    "        \n",
    "    def get_master_df(self):\n",
    "        return self._DF_MASTER;\n",
    "    \n",
    "    def set_master_npz(self, master_npz):\n",
    "        self._NPZ_MASTER = master_df;\n",
    "        \n",
    "    def get_master_npz(self):\n",
    "        return self._NPZ_MASTER\n",
    "    \n",
    "    def get_result_columns(self):\n",
    "        i=1; r=[];\n",
    "        while(i<=20):\n",
    "            r.append('r'+str(i));\n",
    "            i+=1;        \n",
    "        return r;\n",
    "    \n",
    "    def get_draw_columns(self):\n",
    "        i=1; drs=[];\n",
    "        while(i<=80):\n",
    "            drs.append('dr'+str(i));\n",
    "            i+=1;        \n",
    "        return drs;\n",
    "    \n",
    "    def get_depth_columns(self):\n",
    "        i=1; dps=[];\n",
    "        while(i<=80):\n",
    "            dps.append('dp'+str(i));\n",
    "            i+=1;        \n",
    "        return dps;\n",
    "    \n",
    "    def get_count_id(self, df=None):\n",
    "        if(df is None):\n",
    "            count_id = self._COUNT_ID;\n",
    "        else:\n",
    "            count_id = df.shape[0];\n",
    "        return count_id;\n",
    "    \n",
    "    def get_first_id(self, df=None):\n",
    "        if(df is None):\n",
    "            min_id = self._MIN_ID;\n",
    "        else:\n",
    "            min_id = df[:1].index.item();\n",
    "        return min_id;\n",
    "    \n",
    "    def get_last_id(self, df=None):\n",
    "        if(df is None):\n",
    "            max_id = self._MAX_ID;\n",
    "        else:\n",
    "            max_id = df[-1:].index.item();\n",
    "        return max_id;\n",
    "    \n",
    "    def deconstruct_master_df(self):\n",
    "        if(self._DF_IDs is None):\n",
    "            self._DF_IDs, self._DF_R, self._DF_DR, self._DF_DP = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame();\n",
    "\n",
    "            if (self._DF_MASTER is not None ): #or self._DF_MASTER.empty): #empty is an attribute, not a function\n",
    "                print(\"ERROR: Missing Master Dataframe\");\n",
    "            else:\n",
    "                self._DF_IDs = pd.DataFrame(self._DF_MASTER.index);\n",
    "                self._DF_R = self._DF_MASTER.loc[:,self.get_result_columns()]\n",
    "                self._DF_DR = self._DF_MASTER.loc[:,self.get_draw_columns()]\n",
    "                self._DF_DP = self._DF_MASTER.loc[:,self.get_depth_columns()]\n",
    "\n",
    "            return self._DF_IDs, self._DF_R, self._DF_DR, self._DF_DP;\n",
    "    \n",
    "    def df2np(self, df):\n",
    "        if(isinstance(df, pd.DataFrame)):\n",
    "            df = df.to_numpy();\n",
    "        return df;\n",
    "    \n",
    "    def np2df(self, nparray):\n",
    "        if(isinstance(nparray, np.ndarray)):\n",
    "            nparray = pd.DataFrame(nparray);\n",
    "        return nparray;\n",
    "            \n",
    "    def split_xy(self, df):\n",
    "        x, y = pd.DataFrame(), pd.DataFrame();\n",
    "        if not df.empty:\n",
    "           x, y = df[:-1],df[1:];\n",
    "        else:\n",
    "            print(\"Empty dataframe\")\n",
    "        return x,y;\n",
    "        \n",
    "    def print_xy(self, x, y):\n",
    "        x = self.df2np(x);\n",
    "        y= self.df2np(y)\n",
    "        for i in range(len(x)):\n",
    "            print(x[i],y[i])\n",
    "            \n",
    "    def print_xy_prediction(self, y_hat, y_test):\n",
    "        print(\"[Predicted vs Actuual]\")\n",
    "        \n",
    "        #n_input - input rows- number of previous input timesteps t,t-1,t-2,t....n\n",
    "        #t_output - Y timesteps to predict. 0 by default - predicts t+1        \n",
    "    def to_supervised(self, data_df, n_input, t_output=0):\n",
    "        data = self.df2np(data_df);\n",
    "        X, y = list(), list()\n",
    "        ix_start = 0\n",
    "        # step over the entire history one time step at a time\n",
    "        for i in range(len(data)):\n",
    "            # define the end of the input sequence\n",
    "            ix_end = ix_start + n_input\n",
    "            ix_output = ix_end + t_output\n",
    "            # ensure we have enough data for this instance\n",
    "            if ix_output < len(data):\n",
    "                X.append(data[ix_start:ix_end])\n",
    "                y.append(data[ix_output])\n",
    "                # move along one time step\n",
    "                ix_start += 1\n",
    "        return array(X), array(y);\n",
    "    \n",
    "    def create_supervised_package(self, masterDF, startID, nDraws, nInputs, nTests):\n",
    "        #ids, X, Y, X_test, Y_test = np.ndarray([]), np.ndarray([]), np.ndarray([]), np.ndarray([]), np.ndarray([]);\n",
    "        cutOff = nDraws + nInputs + nTests;\n",
    "        nDFs = masterDF[startID:cutOff]\n",
    "        nIDs = self.df2np(pd.DataFrame(nDFs.index))\n",
    "        X_all, Y_all = self.to_supervised(nDFs,nInputs)\n",
    "        \n",
    "        CutSplit = -nTests; #split by 5, uses [:-5] and [-5:]\n",
    "        X, Y, X_test, Y_test = self.xy_split(X_all, Y_all, CutSplit);\n",
    "        IDs, IDs_test =  nIDs[nInputs:CutSplit], nIDs[CutSplit:];\n",
    "        return IDs, X, Y, IDs_test, X_test, Y_test\n",
    "        \n",
    "        \n",
    "    def xy_split(self, X_all, Y_all, CutSplit):\n",
    "        x,y,x_test,y_test = X_all[:CutSplit], Y_all[:CutSplit], X_all[CutSplit:], Y_all[CutSplit:];\n",
    "        return x, y, x_test, y_test;\n",
    "    \n",
    "    def create_new(self, newMasterFile, newMasterDF):\n",
    "        self._FILE_NAME = newMasterFile;\n",
    "        self.derive_folder_path();\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "        \n",
    "        newMasterDF.to_pickle(self._FULL_PATH)\n",
    "        print(\"Saved new file {0}\".format(self._FULL_PATH))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from ipynb.fs.full.ifile import iFile\n",
    "#from ipynb.fs.full.idata import Data\n",
    "\n",
    "class Dataset(iFile):\n",
    "    _ID = None;\n",
    "    _GAME=None\n",
    "    _DATASET = None;\n",
    "    _DATASET_PATH = None;\n",
    "    _FOLDER_TYPE = 'datasets'\n",
    "    _DF_MASTER = None;\n",
    "    \n",
    "    def __init__(self, DatasetID='', FolderPath= 'data/', FileFormat='npz'):\n",
    "        self._ID = DatasetID;\n",
    "        super().__init__(DatasetID, FolderPath, FileFormat)\n",
    "        self.decipher_file_name();\n",
    "        self.derive_folder_path(self._INFO); #you don't need this for model\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "    \n",
    "    def decipher_file_name(self, delimiter=\"_\"):\n",
    "        #if .format is included, remove this first\n",
    "        FN = self._FILE_NAME\n",
    "        FN_PARTS = FN.split(delimiter);\n",
    "        self._INFO['GAME'], self._GAME = FN_PARTS[0], FN_PARTS[0]\n",
    "        self._INFO['xnINPUTS'] = FN_PARTS[1]\n",
    "        self._INFO['nINPUTS'] = self.derive_xninputs(self._INFO['xnINPUTS'])\n",
    "        self._INFO['xnDRAWS'] = FN_PARTS[2]\n",
    "        self._INFO['nDRAWS'] = self.derive_xndraws(self._INFO['xnDRAWS'])\n",
    "        self._INFO['DATA_TYPE'] = FN_PARTS[3] \n",
    "        #check if file format\n",
    "        #self.set_file_format(self._FILE_NAME); #can't use this as we use decimal\n",
    "\n",
    "        return self._FILE_NAME_DECIPHERS;\n",
    "    \n",
    "    #25000=>25k and 25k=>25000\n",
    "    def derive_xndraws(self, xndraws):\n",
    "        nDraw = 0; notation=''\n",
    "        if (type(xndraws) == str):\n",
    "            notation=xndraws[len(xndraws)-1];            \n",
    "            if(type(notation) == int): multiple = 1;\n",
    "            elif (notation=='k'): multiple = 1000;\n",
    "            elif (notation=='m'): multiple = 1000000;\n",
    "            new_st = float(xndraws.replace(notation,''))# change to float 2.5 first\n",
    "            nDraw = int(new_st*multiple) #then covert back to int from float\n",
    "            print(\"xndraw{0}, new_st{1}, multiple{2}, notation{3}\".format(xndraws, new_st, multiple, notation))\n",
    "        elif (type(xndraws) == int):\n",
    "            if(xndraws > 1000000) :\n",
    "                notation = 'm';\n",
    "                nDraw = str(xndraws//1000000)+notation;\n",
    "            elif (xndraws > 1000):\n",
    "                notation = 'k';\n",
    "                nDraw = str(xndraws//1000)+notation;\n",
    "            else:\n",
    "                nDraw = str(xndraws//1);\n",
    "        return nDraw;\n",
    "    \n",
    "    #x15=>15 and 15=>x15\n",
    "    def derive_xninputs(self, xnInputs):\n",
    "        nInputs = 0;\n",
    "        if (type(xnInputs) == str):\n",
    "            #remove first character\n",
    "            nInputs = int(xnInputs[1:]);\n",
    "        elif (type(xnInputs) == int):\n",
    "            nInputs = 'x'+str(xnInputs);        \n",
    "        return nInputs;\n",
    "    \n",
    "\n",
    "    def set_file_format(self, FileName):\n",
    "        #split name and see if file format is included\n",
    "        Fs=FileName.split(\".\");\n",
    "        try:\n",
    "          self._FILE_FORMAT=Fs[1];\n",
    "        except IndexError:\n",
    "          print(\"File format not included in FIle Name\")\n",
    "        return self._FILE_FORMAT;\n",
    "\n",
    "    def derive_file_path(self):\n",
    "        #derive file name from decipher  \n",
    "        FilePath = self._FOLDER_TYPE + '/';\n",
    "        FilePath += self._FILE_NAME;\n",
    "        FilePath += \".\" + self._FILE_FORMAT;\n",
    "        self._FILE_PATH = FilePath;\n",
    "        print(\"[iDataset:derive_file_path] {0}\".format(self._FILE_PATH))\n",
    "        \n",
    "    def load(self):\n",
    "        self._DATASET = np.load(self._FULL_PATH)\n",
    "        print(\"Loading dataset {0}\".format(self._FULL_PATH))\n",
    "        \n",
    "    def load_master_df(self):\n",
    "        if(self._DF_MASTER is None):\n",
    "            masterPkl = self._GAME +\"_master\";\n",
    "            masterDF = Data(masterPkl);\n",
    "            self._DF_MASTER = masterDF._DF_MASTER;\n",
    "            print(\"[iDataset:load_master_df] Loaded master DF\")\n",
    "            \n",
    "    def derive_full_path_by_id(self, newDatasetID):\n",
    "        self._FILE_NAME = newDatasetID; #this is the onlyl thing you need to change\n",
    "        self.decipher_file_name();\n",
    "        self.derive_folder_path(self._INFO); #you don't need this for model\n",
    "        self.derive_file_path();\n",
    "        self.derive_full_path();\n",
    "        \n",
    "    def create_new_by_id(self, DF_Master, newDatasetID, nTests=15):\n",
    "        self.derive_full_path_by_id(newDatasetID);\n",
    "        self.ensure_dirs(); #ensure Full Path exists\n",
    "        #now use file info details self._INFO\n",
    "        \n",
    "        masterPkl = self._INFO['GAME'] +\"_master\";\n",
    "        masterData = Data(masterPkl);\n",
    "        ids, x, y, ids_test, x_test, y_test=masterData.create_supervised_package(DF_Master, 0, self._INFO['nDRAWS'], self._INFO['nINPUTS'], nTests);\n",
    "        \n",
    "        np.savez(self._FULL_PATH, IDs=ids, X=x, Y=y, IDs_test=ids_test, X_test=x_test, Y_test=y_test);\n",
    "        \n",
    "        print(\"Saved new datast file {0}\".format(self._FULL_PATH))\n",
    "        \n",
    "    def derive_new_dataset_id(self, Game, nDraws, nInputs, DataType='dr'):\n",
    "        newDatasetID = Game + \"_\";\n",
    "        newDatasetID += self.derive_xninputs(nInputs) + \"_\";\n",
    "        newDatasetID += self.derive_xndraws(nDraws) + \"_\";\n",
    "        newDatasetID += DataType;\n",
    "        return newDatasetID;\n",
    "        \n",
    "    def create_new(self, DF_Master, startID, nDraws, nInputs, nTests=15, DataType='dr'):        \n",
    "        newDatasetID = self.derive_new_dataset_id(self._INFO['GAME'], nDraws, nInputs, DataType);\n",
    "        \n",
    "        self.create_new_by_id(DF_Master, newDatasetID, nTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.imodel import Model\n",
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "class KER_Model(Model):\n",
    "    _MODEL_PATH = None;\n",
    "    \n",
    "    def __init__(self, ModelID, Dataset):\n",
    "        super().__init__(ModelID, Dataset)\n",
    "        print(\"[KER_Model:__init__]\")\n",
    " \n",
    "    def load(self):\n",
    "        print(\"[KER_Model:load]: Loading {0}\".format(self._FULL_PATH))\n",
    "        pass;\n",
    "    \n",
    "    def save(self):\n",
    "        print(\"[KER_Model:save]: Saving {0}\".format(self._FULL_PATH))\n",
    "    \n",
    "    def load_best_version(self):\n",
    "        pass;\n",
    "    \n",
    "    def load_latest_version(self):\n",
    "        pass;\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.imodel import Model\n",
    "import tensorflow as tfl\n",
    "\n",
    "class TFL_Model(Model):\n",
    "    _MODEL_PATH = None;\n",
    "    \n",
    "    def __init__(self, ModelID, Dataset):\n",
    "        super().__init__(ModelID, Dataset)\n",
    " \n",
    "    def load(self):\n",
    "        print(\"Loading {0}\".format(self._FULL_PATH))\n",
    "        pass;\n",
    "    \n",
    "    def save(self):\n",
    "        print(\"Saving {0}\".format(self._FULL_PATH))\n",
    "    \n",
    "    def load_best_version(self):\n",
    "        pass;\n",
    "    \n",
    "    def load_latest_version(self):\n",
    "        pass;\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xndraw2.528m, new_st2.528, multiple1000000, notationm\n",
      "[iFile:__init__]\n",
      "xndraw2.528m, new_st2.528, multiple1000000, notationm\n",
      "[iFile:derive_folder_path] data/keno/x15/2.528m/\n",
      "[iDataset:derive_file_path] datasets/keno_x15_2.528m_dr.npz\n",
      "[ifile:derive_full_path] ../data/keno/x15/2.528m/datasets/keno_x15_2.528m_dr.npz\n",
      "Loading dataset ../data/keno/x15/2.528m/datasets/keno_x15_2.528m_dr.npz\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.ker_model import KER_Model;\n",
    "from ipynb.fs.full.tfl_model import TFL_Model;\n",
    "from ipynb.fs.full.idataset import Dataset\n",
    "\n",
    "class AI:\n",
    "    _M =None;\n",
    "    _D =None;\n",
    "    _MASTER=None;\n",
    "    _GAME = None;\n",
    "    _API = None;\n",
    "    \n",
    "    def __init__(self, ModelID, DatasetID):\n",
    "        self.load_dataset(DatasetID)\n",
    "        self._D.ensure_dirs();\n",
    "        \n",
    "        self.load_model(ModelID, self._D); #you need x5/25k from datasetfolder\n",
    "        self._M.ensure_dirs();\n",
    "        \n",
    "        print(\"[AI:__init__]\")\n",
    "        pass;\n",
    "\n",
    "    \n",
    "    def setup_model(self, ModelName):\n",
    "        pass;\n",
    "    \n",
    "    def load_model(self, ModelID, Dataset):\n",
    "        info = ModelID.split(\".\");\n",
    "        self._GAME = info[0];\n",
    "        self._API = info[1]\n",
    "        \n",
    "        print(\"Game: {0} API {1}\".format(self._GAME, self._API))\n",
    "        \n",
    "        if (self._API == 'ker'):\n",
    "            self._M = KER_Model(ModelID, Dataset);\n",
    "        elif(self._API == 'tfl'):\n",
    "            self._M = TFL_Model(ModelID, Dataset);\n",
    "            \n",
    "        self._M.load();\n",
    "        print(\"Loaded Model {0}\".format(self._M._FULL_PATH))\n",
    "    \n",
    "    def load_dataset(self, DatasetName):\n",
    "        self._D = Dataset(DatasetName);\n",
    "        self._D.load();\n",
    "        #Dataset is stored in self._D._DATASET[IDs,X,Y,IDs_test,X_test,Y_test]\n",
    "        print(\"Loaded Dataset {0}\".format(self._D._FULL_PATH))\n",
    "    \n",
    "    def save_model(self, Model):\n",
    "        pass;\n",
    "    \n",
    "    def get_model_summary(self, Model):\n",
    "        pass;\n",
    "    \n",
    "    def train_model(self, Model, TrainingDataset):\n",
    "        pass;\n",
    "    \n",
    "    def predict_model(self, Model, TestDataset):\n",
    "        pass;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = AI('ker.1.1','keno_x15_100k_dr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
