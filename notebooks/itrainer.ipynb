{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../itrainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '../itrainer.py'\n",
    "\n",
    "from idataset import Dataset\n",
    "from imodel import Model\n",
    "from ker_model import KER_Model\n",
    "from tfl_model import TFL_Model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, History, CSVLogger\n",
    "from custom_callbacks import cf_callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from db.models import training_session, training_log\n",
    "\n",
    "import os;\n",
    "\n",
    "class Trainer:\n",
    "    _MODEL = None\n",
    "    _DATASET = None\n",
    "    _MODSET_ID = None\n",
    "    _EPOCHS = 10;\n",
    "    _BATCH_SIZE=100;\n",
    "    _CALLBACKS=[]\n",
    "    _INFO={}\n",
    "    _SESSION = None;\n",
    "    \n",
    "    def __init__(self, ModelID, DatasetID, LoadLatestCheckpoint=False):\n",
    "        if (self.is_modset_id(ModelID)):\n",
    "            self._MODSET_ID = ModelID;\n",
    "            modelID, datasetID = self.parse_modset_id(self._MODSET_ID);\n",
    "            \n",
    "            self._DATASET = Dataset(datasetID);\n",
    "            self._DATASET.load()\n",
    "\n",
    "            self._MODEL = Model(modelID, self._DATASET);\n",
    "            self._MODEL.load();\n",
    "        else:\n",
    "            modelID = ModelID;\n",
    "            datasetID = DatasetID;\n",
    "            \n",
    "            self._DATASET = Dataset(datasetID);\n",
    "            self._DATASET.load()\n",
    "\n",
    "            self._MODEL = Model(modelID, self._DATASET);\n",
    "            self._MODEL.load();\n",
    "\n",
    "            self._MODSET_ID = self.derive_modset_id(self._MODEL, self._DATASET)        \n",
    "\n",
    "        if (LoadLatestCheckpoint==True):\n",
    "            self._MODEL.load_latest_checkpoint();\n",
    "        \n",
    "        self._SESSION = training_session.TrainingSession(self._MODSET_ID);\n",
    "            \n",
    "    def derive_modset_id(self, Model, Dataset):\n",
    "        MODSET_ID = Model._INFO['GAME'] \\\n",
    "                            +'.'+  Model._INFO['API'] \\\n",
    "                            +'.'+  Model._INFO['BUILD'] \\\n",
    "                            +'.'+  Model._INFO['MAKE'] \\\n",
    "                            +'.'+  Model._INFO['VERSION'] \\\n",
    "                            + '[' + Dataset._INFO['xnINPUTS'] \\\n",
    "                            +'_'+  Dataset._INFO['xnDRAWS'] \\\n",
    "                            +'_'+  Dataset._INFO['DATA_TYPE'] \\\n",
    "                            + ']';\n",
    "        print(\"Modset ID: {0}\".format(MODSET_ID))\n",
    "        return MODSET_ID;\n",
    "    \n",
    "    def parse_modset_id(self, modsetID):\n",
    "        ids = modsetID.split('[')\n",
    "        mods = ids[0].split('.')\n",
    "        dats = ids[1][:-1].split('_')\n",
    "        model_id = '{0}.{1}.{2}.{3}.{4}'.format(mods[0],mods[1], mods[2], mods[3],mods[4])\n",
    "        dataset_id = '{0}_{1}_{2}_{3}'.format(mods[0],dats[0], dats[1], mods[2])\n",
    "        return model_id, dataset_id;\n",
    "        \n",
    "    def is_modset_id(self, id):\n",
    "        isModsetID = False;\n",
    "        ids = id.split('[');\n",
    "        if len(ids) > 1:\n",
    "            isModsetID = True;\n",
    "        return isModsetID;\n",
    "        \n",
    "    \n",
    "    def set_callbacks(self, Callbacks={}):\n",
    "         for key, val in Callbacks.items():\n",
    "            if(key == 'per_epoch'):\n",
    "                self.set_checkpoint_per_epoch(val);\n",
    "            if(key=='csv_logger'):\n",
    "                self.get_csv_history(val);\n",
    "            if(key=='upload_history'):\n",
    "                self.upload_history_per_epoch(val);\n",
    "            if(key=='custom_callbacks'):\n",
    "                self.set_custom_callbacks(val);\n",
    "                \n",
    "    def set_custom_callbacks(self, CallBackName):\n",
    "        custom_callbacks = cf_callbacks();\n",
    "        custom_callbacks.set_session(self._SESSION)\n",
    "        self._CALLBACKS.append(custom_callbacks)\n",
    "        print(\"[itrainer:set_custom_callbacks] added custom_callback {0}\".format(CallBackName))\n",
    "                \n",
    "                \n",
    "    def get_csv_history(self, PerEpoch=1):\n",
    "        current_folder = os.getcwd() #gives a array with current working folder i.e notebook folder\n",
    "        db_folder = current_folder + '/db/'\n",
    "        csv_file= db_folder + 'csv_logs.csv'\n",
    "        csv_logger = CSVLogger(csv_file, separator=\",\", append=True);\n",
    "        self._CALLBACKS.append(csv_logger)\n",
    "        print(\"[itrainer:get_csv_histry] added csv_logger callback {0}\".format(csv_file))\n",
    "        \n",
    "    def upload_history_per_epoch(self, PerEpoch=1):\n",
    "        history = History();\n",
    "        #self._CALLBACKS.append(chkpnt)\n",
    "        print(\"[itrainer:uplload_histry_per_epoch] added db_upload_history callback\")\n",
    "            \n",
    "    \n",
    "    def set_checkpoint_per_epoch(self, PerEpoch=5):\n",
    "        file_name = self._MODEL._INFO['GAME'] + '.';\n",
    "        file_name += self._MODEL._INFO['API']  + '.';\n",
    "        file_name += self._MODEL._INFO['BUILD']  + '.';\n",
    "        file_name += self._MODEL._INFO['MAKE']  + '.';\n",
    "        #file_name += 'e'+str(self._MODEL._CHECKPOINT_EPOCH)+'+'+int('{epoch:04d}') ;\n",
    "        file_name += 'e{epoch:04d}' ;\n",
    "        chkpnt_file = self._MODEL._CHECKPOINTS_FOLDER + file_name;\n",
    "        \n",
    "        self._MODEL.derive_checkpoints_folder();        \n",
    "        self._MODEL.ensure_dirs(chkpnt_file); #ensure checkpnt folder exists, folder doesn't work, so use filepath\n",
    "        \n",
    "        \n",
    "        chkpnt = ModelCheckpoint(            \n",
    "            chkpnt_file,\n",
    "            monitor='loss',\n",
    "            verbose=0,\n",
    "            save_best_only=False,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            period=PerEpoch);\n",
    "        self._CALLBACKS.append(chkpnt)\n",
    "        \n",
    "        \n",
    "        chkpnt_file_ckpt = self._MODEL._CHECKPOINTS_FOLDER + file_name + '.ckpt';\n",
    "        chkpnt_ckpt = ModelCheckpoint(            \n",
    "            chkpnt_file_ckpt,\n",
    "            monitor='loss',\n",
    "            verbose=0,\n",
    "            save_best_only=False,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            period=PerEpoch);\n",
    "        self._CALLBACKS.append(chkpnt_ckpt)\n",
    "        \n",
    "        \n",
    "        chkpnt_file_h5 = self._MODEL._CHECKPOINTS_FOLDER + file_name + '.h5';\n",
    "        chkpnt_h5 = ModelCheckpoint(            \n",
    "            chkpnt_file_h5,\n",
    "            monitor='loss',\n",
    "            verbose=0,\n",
    "            save_best_only=False,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            period=PerEpoch);\n",
    "        self._CALLBACKS.append(chkpnt_h5)\n",
    "        print(\"[itrainer:set_checkpoint_per_epoch] added model_checkpoint callback\")\n",
    "    \n",
    "    def train(self, Epochs=10, BatchSize=100, Callbacks={}, Verbose=0):\n",
    "        self._EPOCHS = Epochs;\n",
    "        self._BATCH_SIZE = BatchSize;\n",
    "        self.set_callbacks(Callbacks);\n",
    "        \n",
    "        self._SESSION.start_session(self._MODEL._CHECKPOINT_EPOCH, self._EPOCHS, self._BATCH_SIZE)\n",
    "                \n",
    "        self._INFO['HISTORY'] = self._MODEL._M.fit( x= self._DATASET._D['X'] \\\n",
    "                            , y= self._DATASET._D['Y'] \\\n",
    "                            , batch_size= self._BATCH_SIZE \\\n",
    "                            , epochs= self._EPOCHS \\\n",
    "                            , verbose= Verbose \\\n",
    "                            , callbacks=self._CALLBACKS \\\n",
    "                            #, validation_split=0.0 \\\n",
    "                            #, validation_data=None \\\n",
    "                            , shuffle = False \\\n",
    "                            #, class_weight=None \\\n",
    "                            #, sample_weight=None \\\n",
    "                            , initial_epoch = self._MODEL._CHECKPOINT_EPOCH \\\n",
    "                            #, steps_per_epoch=None \\\n",
    "                            #, validation_steps=None \\\n",
    "                            #, validation_freq=1 \\\n",
    "                            #, max_queue_size=10 \\\n",
    "                            #, workers=1 \\\n",
    "                            #, use_multiprocessing=False\\\n",
    "                            );\n",
    "        \n",
    "        self._SESSION.end_session();\n",
    "        \n",
    "    \n",
    "    def plt_history(self):\n",
    "        legends=[]\n",
    "        print(self._INFO['HISTORY'].history)\n",
    "        for key in self._INFO['HISTORY'].history:\n",
    "            plt.plot(self._INFO['HISTORY'].history[key])\n",
    "            legends.append(key)\n",
    "            plt.ylabel(key)\n",
    "        \n",
    "        plt.title('model {0}'.format(\"lOSS VS ACC\"))\n",
    "        plt.legend(legends, loc='upper left')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self._HISTORY.history['loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.show()\n",
    "\n",
    "    def plt_db_logs(self, ModsetID=None):\n",
    "        if(ModsetID == None):\n",
    "            ModsetID = self._MODSET_ID;\n",
    "        \n",
    "        trainingLog = training_log.TrainingLog(ModsetID);\n",
    "        df_logs = trainingLog.get_dataframe();\n",
    "        df_logs.set_index('train_log_id', inplace=True)\n",
    "        logs = df_logs.loc[df_logs.modset_id == ModsetID ]\n",
    "\n",
    "        logs.plot(kind='line',x='epoch',y='loss',ax=plt.gca())\n",
    "        logs.plot(kind='line',x='epoch',y='metric_value', legend='precision_top10', color='red', ax=plt.gca())\n",
    "\n",
    "        plt.title('{0} - Loss vs {1}'.format(ModsetID, logs['metric_name'].unique()[0]))\n",
    "        plt.legend(['loss',logs['metric_name'].unique()[0]])\n",
    "        plt.show()\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
